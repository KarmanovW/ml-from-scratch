{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d89opnmZ0SD9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "\n",
        "    class _Node:\n",
        "        def __init__(self, index, t, true_branch, false_branch):\n",
        "            self.index = index # индекс признака, по которому ведётся сравнение с порогом в этом узле\n",
        "            self.t = t # значение порога\n",
        "            self.true_branch = true_branch # поддерево, удовлетворяющее условию в узле\n",
        "            self.false_branch = false_branch # поддерево, не удовлетворяющее условию в узле\n",
        "\n",
        "\n",
        "    class _Leaf:\n",
        "        def __init__(self, labels):\n",
        "            self.prediction = self.predict(labels) # y_pred\n",
        "\n",
        "        def predict(self, labels):\n",
        "            classes, counts = np.unique(labels, return_counts=True)\n",
        "            return classes[np.argmax(counts)] #возвращаем класс с максимальной частотой\n",
        "            #return np.mean(labels)\n",
        "\n",
        "    def __init__(self, min_leaf=5, max_depth=None, criterion='gini'):\n",
        "        self.min_leaf = min_leaf\n",
        "        self.max_depth = max_depth\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "\n",
        "    def _gini(self, labels): # вероятность ошибочной классификации случайного объекта G=0 → все объекты одного класса\n",
        "        if len(labels) == 0:\n",
        "            return 0\n",
        "\n",
        "        counts = np.unique(labels, return_counts=True)[1]\n",
        "        p = counts / len(labels)\n",
        "\n",
        "        return 1 - np.sum(p ** 2)\n",
        "\n",
        "\n",
        "    def _entropy(self, labels): # мера неопределённости H=0 → полная определённость\n",
        "        if len(labels) == 0:\n",
        "            return 0\n",
        "\n",
        "        counts = np.unique(labels, return_counts=True)[1]\n",
        "        p = counts / len(labels)\n",
        "\n",
        "        return -np.sum(p * np.log2(p + 1e-12))\n",
        "\n",
        "\n",
        "    def _impurity(self, labels):\n",
        "        if self.criterion == \"entropy\":\n",
        "            return self._entropy(labels)\n",
        "\n",
        "        return self._gini(labels)\n",
        "\n",
        "\n",
        "    def _quality(self, left_labels, right_labels, current_impurity): #Насколько уменьшилась неоднородность после разбиения. Чем больше Q — тем лучше сплит.\n",
        "        S = len(left_labels) / (len(left_labels) + len(right_labels))\n",
        "        return current_impurity - S * self._impurity(left_labels) - (1 - S) * self._impurity(right_labels)\n",
        "\n",
        "\n",
        "    def _split(self, data, labels, index, t): # t порог разбиения\n",
        "        true_mask = data[:, index] <= t\n",
        "        false_mask = data[:, index] > t\n",
        "\n",
        "        return data[true_mask], data[false_mask], labels[true_mask], labels[false_mask]\n",
        "\n",
        "\n",
        "    def _find_best_split(self, data, labels):\n",
        "        best_quality = 0    # ЛУЧШЕЕ найденное уменьшение неоднородности\n",
        "        best_t = None # Лучший порог разбиения\n",
        "        best_index = None # Индекс признака, по которому делим\n",
        "\n",
        "        current_impurity = self._impurity(labels)   # Неоднородность (gini или entropy) в текущем узле ДО разбиения\n",
        "        n_features = data.shape[1]    # Количество признаков (число столбцов)\n",
        "\n",
        "        for index in range(n_features):\n",
        "            values = np.unique(data[:, index])\n",
        "\n",
        "            if len(values) == 1: # Если у признака одно значение — по нему нельзя делить\n",
        "                continue\n",
        "\n",
        "            thresholds = (values[:-1] + values[1:]) / 2 # Возможные пороги — середины между соседними значениями\n",
        "\n",
        "            for t in thresholds:\n",
        "                true_labels, false_labels = self._split(data, labels, index, t)[2:]\n",
        "\n",
        "                if len(true_labels) < self.min_leaf or len(false_labels) < self.min_leaf:  # Проверка минимального размера листа\n",
        "                    continue\n",
        "\n",
        "                q = self._quality(true_labels, false_labels, current_impurity)             # Считаем качество разбиения (information gain)\n",
        "\n",
        "                if q > best_quality:             # Если текущее разбиение лучше всех предыдущих — запоминаем его\n",
        "                    best_quality = q\n",
        "                    best_t = t\n",
        "                    best_index = index\n",
        "\n",
        "        return best_quality, best_t, best_index\n",
        "\n",
        "\n",
        "    def _build_tree(self, data, labels, depth=0):\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            return self._Leaf(labels)\n",
        "\n",
        "        best_quality, best_t, best_index = self._find_best_split(data, labels)\n",
        "\n",
        "\n",
        "        if best_quality == 0:\n",
        "            return self._Leaf(labels)\n",
        "\n",
        "        true_data, false_data, true_labels, false_labels = self._split(\n",
        "            data, labels, best_index, best_t\n",
        "        )\n",
        "\n",
        "        true_branch = self._build_tree(true_data, true_labels, depth + 1) # Рекурсивно строим левое поддерево. Увеличиваем глубину на 1\n",
        "        false_branch = self._build_tree(false_data, false_labels, depth + 1)   # Рекурсивно строим правое поддерево\n",
        "\n",
        "        return self._Node(best_index, best_t, true_branch, false_branch)  # Возвращаем внутренний узел дерева\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(np.array(X), np.array(y))\n",
        "\n",
        "\n",
        "    def _classify_object(self, obj, node): #спуск по дереву\n",
        "        if isinstance(node, self._Leaf): # если текущий узел — лист\n",
        "            return node.prediction\n",
        "\n",
        "        if obj[node.index] <= node.t:\n",
        "            return self._classify_object(obj, node.true_branch) #левая ветка рекурсивно если объект удовлетворяет условию узла\n",
        "\n",
        "        return self._classify_object(obj, node.false_branch) #правая ветка\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._classify_object(obj, self.tree) for obj in X]) #y_pred\n",
        "\n",
        "\n",
        "    def score(self, X, y):  # вычисляет долю верных предсказаний (accuracy)\n",
        "        y_pred = self.predict(X)\n",
        "        return np.mean(y_pred == y)"
      ],
      "metadata": {
        "id": "uGR6ls0m0mMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Тестирование\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Генерация данных\n",
        "    np.random.seed(42)\n",
        "    n = 300\n",
        "\n",
        "    # Класс 0\n",
        "    X0 = np.random.randn(n, 2) + np.array([0, 0])\n",
        "    y0 = np.zeros(n)\n",
        "\n",
        "    # Класс 1\n",
        "    X1 = np.random.randn(n, 2) + np.array([3, 3])\n",
        "    y1 = np.ones(n)\n",
        "\n",
        "    # Объединяем\n",
        "    X = np.vstack([X0, X1])\n",
        "    y = np.hstack([y0, y1])\n",
        "\n",
        "    # Перемешиваем\n",
        "    idx = np.random.permutation(len(X))\n",
        "    X = X[idx]\n",
        "    y = y[idx]\n",
        "\n",
        "    # Обучение модели\n",
        "    model = DecisionTree(min_leaf=5, max_depth=5, criterion='gini')\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Предсказания и качество\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = model.score(X, y)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILexKOCp0pM-",
        "outputId": "f1443230-6505-4098-de9d-05a5b5dcd904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9817\n"
          ]
        }
      ]
    }
  ]
}